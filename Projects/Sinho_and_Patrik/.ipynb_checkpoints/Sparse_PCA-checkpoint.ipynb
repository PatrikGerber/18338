{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we implement the 'Diagonal Thresholding' algorithm for sparse PCA introduced in https://www.tandfonline.com/doi/pdf/10.1198/jasa.2009.0121 . \n",
    "(maybe look at http://www.mit.edu/~yash/PAPERS/sparse.pdf ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots, LinearAlgebra, Random, Distributions, Statistics, MultivariateStats, StatsBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalize_columns (generic function with 1 method)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Takes in row-vector θ and outputs n samples from the Gaussian spiked covariance model\n",
    "function spiked(θ, n)\n",
    "#     θ = [sqrt(s)^(-1) for _ in 1:s]\n",
    "#     θ = vcat(θ, zeros(d - s))'\n",
    "    θ .* rand(Normal(), n) + rand(Normal(), n, size(θ)[2])\n",
    "end\n",
    "\n",
    "function embed(I, v)\n",
    "    arr = zeros(length(I), size(v)[2])\n",
    "    counter = 1\n",
    "    for index = 1:length(I)\n",
    "        if I[index]\n",
    "            arr[index, :] = v[counter, :]\n",
    "            counter += 1\n",
    "        end\n",
    "    end\n",
    "    return arr\n",
    "end\n",
    "\n",
    "function normalize_columns(X)\n",
    "    m = size(X)[2]\n",
    "    for col = 1:m\n",
    "        column = X[:, col]\n",
    "        n = norm(column)\n",
    "        if n != 0\n",
    "            X[:, col] = column .* n^(-1)\n",
    "        end\n",
    "    end\n",
    "    return X\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we set up the model and generate a sample from the spiked covariance ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples\n",
    "n = 1000000\n",
    "# Number of dimensions\n",
    "d = 100\n",
    "# Sparsity of the principal eigenvector\n",
    "s = 10\n",
    "\n",
    "# Constructing the principal eigenvector\n",
    "θ = [sqrt(s)^(-1) for _ in 1:s]\n",
    "θ = vcat(θ, zeros(d - s))'\n",
    "# Generating a sample from the spiked covariance ensemble\n",
    "X = spiked(θ, n);\n",
    "ef = eigen(Symmetric(cov(X)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SPCA (generic function with 2 methods)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function SPCA(X, s)\n",
    "    n = size(X)[1]\n",
    "    d = size(X)[2]\n",
    "    \n",
    "     # Step 2.: finding the top variances and storing in I\n",
    "#     vars = var(X, dims=1)\n",
    "#     sortperm(vars)[end - s:end]\n",
    "#     α = 0.5\n",
    "#     σ² = median(vars)\n",
    "#     cutoff = α * √(n\\log(n))\n",
    "#     I = vars .> σ² * (1 + cutoff)\n",
    "#     k = sum(I)\n",
    "    \n",
    "    # Alternative step 2.: we just use the top 's' variances where 's' is our guess of the true sparsity parameter\n",
    "    vars = var(X, dims=1)[1, :]\n",
    "    indexes = sortperm(vars)[end - s + 1:end]\n",
    "    I = [0 for _ = 1:d]\n",
    "    I[indexes] .= 1\n",
    "    I =  BitArray{1}(I)\n",
    "    k = sum(I)\n",
    "    \n",
    "\n",
    "    # Step 3.: performing PCA on subset I of matrix\n",
    "    Y = X[:, I[:]]\n",
    "    Σ = cov(Y)\n",
    "\n",
    "    # ef = eigen(Symmetric(Σ), k:k)\n",
    "    ef = eigen(Symmetric(Σ))\n",
    "    v = ef.vectors\n",
    "\n",
    "    # Step 4.: thresholding the resulting eigenvectors\n",
    "    τ = [mad(v[column, :], normalize = false) for column = 1:size(v)[2]].*(0.6745^(-1))*0.1\n",
    "    v = v .* (broadcast(abs, v) .> (1* τ * √(2 * log(k))))\n",
    "    v = normalize_columns(v)\n",
    "\n",
    "    # Step 5.: returning to original dimension\n",
    "    u = embed(I, v);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = SPCA(X, 3*s);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = v[:, end]\n",
    "θ = [θ[i] for i = 1:length(θ)]\n",
    "w = ef.vectors[:, end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0021387117067153474\n",
      "0.013158589402223773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100-element Array{Float64,1}:\n",
       "  0.31594856424427337  \n",
       "  0.31680102252436393  \n",
       "  0.3154131724091086   \n",
       "  0.3170691442223806   \n",
       "  0.31584858732980675  \n",
       "  0.31583188640484894  \n",
       "  0.3156498935718252   \n",
       "  0.3175580829124475   \n",
       "  0.3156006197000178   \n",
       "  0.3162829150720248   \n",
       "  0.001535027026226849 \n",
       " -0.0028610738743494193\n",
       " -8.832779597605182e-5 \n",
       "  ⋮                    \n",
       " -0.0024566507343141376\n",
       " -0.002541573276072286 \n",
       " -0.0002599350967441458\n",
       "  0.002198427743180153 \n",
       " -0.0007864425554248919\n",
       " -0.0002785856721117634\n",
       "  0.0002453797445823576\n",
       "  3.991707709314866e-5 \n",
       "  0.0021804459177401474\n",
       "  0.0015798561955154625\n",
       "  0.0036472346714008508\n",
       "  0.001936065003344276 "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(min(norm(u - θ), norm(u + θ)))\n",
    "println(min(norm(w - θ), norm(w + θ)))\n",
    "w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
